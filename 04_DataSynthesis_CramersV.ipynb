{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4e6c4b2-67cb-410e-8659-255620b7791f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  hourswrk  incometot  weekswrk  abident  sex  tenure  urban  workfull  \\\n",
      "0   21      40.0    14900.0      48.0        2    1       1      2       1.0   \n",
      "1    8       NaN        NaN       NaN        2    2       2      2       NaN   \n",
      "2   85       0.0    19800.0       NaN        2    1       2      2       NaN   \n",
      "3   42      40.0    16800.0      30.0        2    2       2      2       1.0   \n",
      "4   28       0.0      301.0       NaN        1    1       2      1       NaN   \n",
      "\n",
      "   birthplmom  ...  marstat  tranwork  relate  degree  occupation  immigyear  \\\n",
      "0           1  ...        1       1.0       3     5.0         5.0        NaN   \n",
      "1           1  ...        1       NaN       3     NaN         NaN        NaN   \n",
      "2           1  ...        6       NaN       1     1.0         NaN        NaN   \n",
      "3           2  ...        2       3.0       2     2.0         9.0        2.0   \n",
      "4           1  ...        1       NaN       3     2.0         NaN        NaN   \n",
      "\n",
      "   minority  relig  industry  birthplace  \n",
      "0        13      8      17.0           7  \n",
      "1        13     16       NaN           7  \n",
      "2        13      2       NaN           7  \n",
      "3         4      4      13.0          37  \n",
      "4        13      2       NaN           7  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "['age', 'hourswrk', 'incometot', 'weekswrk', 'abident', 'sex', 'tenure', 'urban', 'workfull', 'birthplmom', 'birthplpop', 'citizen', 'classwork', 'empstat', 'language', 'marstat', 'tranwork', 'relate', 'degree', 'occupation', 'immigyear', 'minority', 'relig', 'industry', 'birthplace']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading Canada dataset\n",
    "canada2011 = pd.read_csv('/Users/idilalp/Desktop/erp datasets/canada2011.csv')\n",
    "\n",
    "# Viewing first few rows and column names\n",
    "print(canada2011.head())\n",
    "print(canada2011.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a675cec1-b9d4-4143-b0aa-6b37212cc245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32149 entries, 0 to 32148\n",
      "Data columns (total 25 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   age         32149 non-null  int64  \n",
      " 1   hourswrk    26054 non-null  float64\n",
      " 2   incometot   26054 non-null  float64\n",
      " 3   weekswrk    18888 non-null  float64\n",
      " 4   abident     32149 non-null  int64  \n",
      " 5   sex         32149 non-null  int64  \n",
      " 6   tenure      32149 non-null  int64  \n",
      " 7   urban       32149 non-null  int64  \n",
      " 8   workfull    18290 non-null  float64\n",
      " 9   birthplmom  32149 non-null  int64  \n",
      " 10  birthplpop  32149 non-null  int64  \n",
      " 11  citizen     32149 non-null  int64  \n",
      " 12  classwork   18888 non-null  float64\n",
      " 13  empstat     26054 non-null  float64\n",
      " 14  language    32149 non-null  int64  \n",
      " 15  marstat     32149 non-null  int64  \n",
      " 16  tranwork    17548 non-null  float64\n",
      " 17  relate      32149 non-null  int64  \n",
      " 18  degree      26054 non-null  float64\n",
      " 19  occupation  18888 non-null  float64\n",
      " 20  immigyear   5308 non-null   float64\n",
      " 21  minority    32149 non-null  int64  \n",
      " 22  relig       32149 non-null  int64  \n",
      " 23  industry    18888 non-null  float64\n",
      " 24  birthplace  32149 non-null  int64  \n",
      "dtypes: float64(11), int64(14)\n",
      "memory usage: 6.1 MB\n"
     ]
    }
   ],
   "source": [
    "canada2011.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8679ec3c-d30a-4652-9b3d-65ff8c212033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from synthpop import CARTMethod, MissingDataHandler, DataProcessor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings \n",
    "import synthpop.method.cart\n",
    "synthpop.method.cart.warnings = warnings  \n",
    "\n",
    "metadata = {\n",
    "    'age': 'numerical',          \n",
    "    'hourswrk': 'numerical',\n",
    "    'incometot': 'numerical',\n",
    "    'weekswrk': 'numerical',\n",
    "    'abident': 'categorical',\n",
    "    'sex': 'categorical',\n",
    "    'tenure': 'categorical',\n",
    "    'urban': 'categorical',\n",
    "    'workfull': 'numerical',\n",
    "    'birthplmom': 'categorical',\n",
    "    'birthplpop': 'categorical',\n",
    "    'citizen': 'categorical',\n",
    "    'classwork': 'numerical',\n",
    "    'empstat': 'categorical',\n",
    "    'language': 'categorical',\n",
    "    'marstat': 'categorical',\n",
    "    'tranwork': 'categorical',\n",
    "    'relate': 'categorical',\n",
    "    'degree': 'categorical',\n",
    "    'occupation': 'categorical',\n",
    "    'immigyear': 'numerical',\n",
    "    'minority': 'categorical',\n",
    "    'relig': 'categorical',\n",
    "    'industry': 'categorical',\n",
    "    'birthplace': 'categorical'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b275d83-67fa-450c-87bd-87521529e2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Data Types: {'age': 'numerical', 'hourswrk': 'numerical', 'incometot': 'numerical', 'weekswrk': 'numerical', 'abident': 'categorical', 'sex': 'categorical', 'tenure': 'categorical', 'urban': 'categorical', 'workfull': 'numerical', 'birthplmom': 'categorical', 'birthplpop': 'categorical', 'citizen': 'categorical', 'classwork': 'numerical', 'empstat': 'categorical', 'language': 'categorical', 'marstat': 'categorical', 'tranwork': 'categorical', 'relate': 'categorical', 'degree': 'categorical', 'occupation': 'categorical', 'immigyear': 'numerical', 'minority': 'categorical', 'relig': 'categorical', 'industry': 'categorical', 'birthplace': 'categorical'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Column Data Types:\", metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d753fc7-c0fc-44af-9744-8ffa9bf71d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data:\n",
      "age               0\n",
      "hourswrk       6095\n",
      "incometot      6095\n",
      "weekswrk      13261\n",
      "abident           0\n",
      "sex               0\n",
      "tenure            0\n",
      "urban             0\n",
      "workfull      13859\n",
      "birthplmom        0\n",
      "birthplpop        0\n",
      "citizen           0\n",
      "classwork     13261\n",
      "empstat        6095\n",
      "language          0\n",
      "marstat           0\n",
      "tranwork      14601\n",
      "relate            0\n",
      "degree         6095\n",
      "occupation    13261\n",
      "immigyear     26841\n",
      "minority          0\n",
      "relig             0\n",
      "industry      13261\n",
      "birthplace        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Processing missing data\n",
    "print(\"Missing data:\")\n",
    "print(canada2011.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0ba160-ecb0-4dfd-9b20-4077f2ab79a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_handler = MissingDataHandler()\n",
    "missingness_dict = md_handler.detect_missingness(canada2011)\n",
    "print(\"Detected missingness type:\", missingness_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2599b9f3-1124-45ea-bab2-753da34ad7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "canada_real = md_handler.apply_imputation(canada2011, missingness_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "886bc459-029c-4961-baba-ec4e59bbe4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data:\n",
      "age           0\n",
      "hourswrk      0\n",
      "incometot     0\n",
      "weekswrk      0\n",
      "abident       0\n",
      "sex           0\n",
      "tenure        0\n",
      "urban         0\n",
      "workfull      0\n",
      "birthplmom    0\n",
      "birthplpop    0\n",
      "citizen       0\n",
      "classwork     0\n",
      "empstat       0\n",
      "language      0\n",
      "marstat       0\n",
      "tranwork      0\n",
      "relate        0\n",
      "degree        0\n",
      "occupation    0\n",
      "immigyear     0\n",
      "minority      0\n",
      "relig         0\n",
      "industry      0\n",
      "birthplace    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing data:\")\n",
    "print(canada_real.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d48aec-66ce-4c4f-8b89-fd6a0bee3d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data:\n",
      "    age   hourswrk     incometot   weekswrk  abident  sex  tenure  urban  \\\n",
      "0  21.0  40.000000  14900.000000  48.000000        1    0       0      1   \n",
      "1   8.0  22.934789  36209.700622  42.407349        1    1       1      1   \n",
      "2  85.0   0.000000  19800.000000  42.407349        1    0       1      1   \n",
      "3  42.0  40.000000  16800.000000  30.000000        1    1       1      1   \n",
      "4  28.0   0.000000    301.000000  42.407349        0    0       1      0   \n",
      "\n",
      "   workfull  birthplmom  ...  marstat  tranwork  relate  degree  occupation  \\\n",
      "0       1.0           0  ...        0         0       2       4           4   \n",
      "1       1.0           0  ...        0         1       2       2           4   \n",
      "2       1.0           0  ...        5         1       0       0           4   \n",
      "3       1.0           1  ...        1         2       1       1           8   \n",
      "4       2.0           0  ...        0         1       2       1           4   \n",
      "\n",
      "   immigyear  minority  relig  industry  birthplace  \n",
      "0   7.469857         4     14         9          37  \n",
      "1   7.469857         4      7         2          37  \n",
      "2   7.469857         4      8         2          37  \n",
      "3   2.000000         7     10         5          30  \n",
      "4   7.469857         4      8         2          37  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: Instantiating the DataProcessor with column_dtypes\n",
    "processor = DataProcessor(metadata)\n",
    "\n",
    "#  Preprocessing the data: transforms raw data into a numerical format\n",
    "processed_data = processor.preprocess(canada_real)\n",
    "print(\"Processed data:\")\n",
    "print(processed_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd5d923-9fea-473f-a3fa-90c09026c812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the CART method\n",
    "cart = CARTMethod(metadata, smoothing=True, proper=True, minibucket=5, random_state=42)\n",
    "cart.fit(processed_data)\n",
    "keepdims=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13478dfd-f0ee-4279-9b92-48654ef3b3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view processedsyntheti data\n",
    "canada_synth_processed = cart.sample(len(canada_real))\n",
    "print(\"Synthetic processed data:\")\n",
    "display(canada_synth_processed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e59298-5095-4eaa-9f9a-f6c5502dcd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view postprocessed synthetic data in the original format\n",
    "canada_synth = processor.postprocess(canada_synth_processed)\n",
    "print(\"Synthetic data in original format:\")\n",
    "display(canada_synth.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e43b06-6bab-4c56-9694-2ec155b9bb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounding age to make it integer\n",
    "canada_synth['age'] = canada_synth['age'].round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ee32d-9f63-4a70-aa50-05fdead1cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view full synthic data\n",
    "print(\"Synthetic data in original format:\")\n",
    "display(canada_synth.head())\n",
    "canada_synth.to_csv('canada_synth.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83451ca-8e04-47d0-820e-d03178013be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show real data\n",
    "print(canada_real.head())\n",
    "\n",
    "# saving the real dataset:\n",
    "canada_real.to_csv('canada_real.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f2772e-ecd4-42f7-bb6a-4c8a61e4b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate synthetic data\n",
    "from synthpop.metrics import (\n",
    "                MetricsReport,\n",
    "                EfficacyMetrics,\n",
    "                DisclosureProtection\n",
    "            )\n",
    "\n",
    "#  Diagnostic report\n",
    "report = MetricsReport(canada_real, canada_synth, metadata)\n",
    "report_df = report.generate_report()\n",
    "print(\"=== Diagnostic Report ===\")\n",
    "display(report_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a8e81-7112-4256-b2c5-4a8b4c937b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save datasets\n",
    "canada_synth.to_csv(\"/Users/idilalp/Desktop/canada_synth.csv\", index=False)\n",
    "canada_real.to_csv(\"/Users/idilalp/Desktop/canada_real.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e672615-d44f-40f6-b158-ab0fc39affbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading full datasets\n",
    "canada_real = pd.read_csv(\"/Users/idilalp/Desktop/canada_real.csv\")\n",
    "canada_synth = pd.read_csv(\"/Users/idilalp/Desktop/canada_synth.csv\")\n",
    "\n",
    "# Defining the relevant columns: 6 keys + 3 targets\n",
    "relevant_columns = ['age', 'sex', 'marstat', 'minority', 'empstat', 'birthplace',\n",
    "                    'relig', 'citizen', 'tenure']\n",
    "\n",
    "# Subsetting and reorder columns\n",
    "canada_real_subset = canada_real[relevant_columns].copy()\n",
    "canada_synth_subset = canada_synth[relevant_columns].copy()\n",
    "\n",
    "# Rounding all numeric values to integers and cast to string\n",
    "canada_real_subset = canada_real_subset.applymap(lambda x: str(int(round(float(x)))) if pd.notnull(x) else \"\")\n",
    "canada_synth_subset = canada_synth_subset.applymap(lambda x: str(int(round(float(x)))) if pd.notnull(x) else \"\")\n",
    "\n",
    "# Saving to CSV \n",
    "canada_real_subset.to_csv(\"/Users/idilalp/Desktop/canada2011_tcap_real.csv\", index=False)\n",
    "canada_synth_subset.to_csv(\"/Users/idilalp/Desktop/canada2011_tcap_synth.csv\", index=False)\n",
    "\n",
    "print(\"Cleaned datasets saved for TCAP analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d499cf-e450-4f19-b09d-a802589afaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "canada_real_subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c59857-7c23-4bbe-b4d2-bc2fa4882f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "canada_synth_subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9436e705-6a8c-4092-b5e1-3c84753f315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creste df\n",
    "real_clean = pd.read_csv(\"/Users/idilalp/Desktop/canada2011_tcap_real.csv\")\n",
    "synth_clean = pd.read_csv(\"/Users/idilalp/Desktop/canada2011_tcap_synth.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc25b4d-172e-4c2c-9c0a-479dca5b3d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting the data for each target with full key set\n",
    "subset_columns = ['age', 'sex', 'marstat', 'minority', 'empstat', 'birthplace', 'relig']\n",
    "\n",
    "real_subset = real_clean[subset_columns].copy()\n",
    "synth_subset = synth_clean[subset_columns].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55f2b67-7459-44c8-87e6-b03cb6462ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved datasets with 6 keys + target (relig)!\n"
     ]
    }
   ],
   "source": [
    "# saving subset for the religion target\n",
    "real_subset.to_csv(\"canada2011_tcap_real_relig.csv\", index=False)\n",
    "synth_subset.to_csv(\"canada2011_tcap_synth_relig.csv\", index=False)\n",
    "\n",
    "print(\"Saved datasets with 6 keys + target (relig)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6118e76-e3cf-4923-931f-8aac5e76e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Build Desktop paths\n",
    "desktop = os.path.expanduser(\"~/Desktop\")\n",
    "real_path = os.path.join(desktop, \"canada2011_tcap_real_relig.csv\")\n",
    "synth_path = os.path.join(desktop, \"canada2011_tcap_synth_relig.csv\")\n",
    "\n",
    "# Save to Desktop\n",
    "real_subset.to_csv(real_path, index=False)\n",
    "synth_subset.to_csv(synth_path, index=False)\n",
    "\n",
    "print(f\"Saved to:\\n{real_path}\\n{synth_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec7d0d2-ef4d-4266-8a88-13b9c41ac63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeating the same process for other targets\n",
    "subset_columns2 = ['age', 'sex', 'marstat', 'minority', 'empstat', 'birthplace', 'citizen']\n",
    "\n",
    "real_subset2 = real_clean[subset_columns2].copy()\n",
    "synth_subset2 = synth_clean[subset_columns2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6ad35df0-e475-4efa-821d-f51785380e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved datasets with 6 keys + target (citizen)!\n"
     ]
    }
   ],
   "source": [
    "real_subset2.to_csv(\"canada2011_tcap_real_citizen.csv\", index=False)\n",
    "synth_subset2.to_csv(\"canada2011_tcap_synth_citizen.csv\", index=False)\n",
    "\n",
    "print(\" Saved datasets with 6 keys + target (citizen)!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64966a3a-f653-4f33-a90d-39a8d0141fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Build Desktop paths\n",
    "desktop = os.path.expanduser(\"~/Desktop\")\n",
    "real_path = os.path.join(desktop, \"canada2011_tcap_real_citizen.csv\")\n",
    "synth_path = os.path.join(desktop, \"canada2011_tcap_synth_citizen.csv\")\n",
    "\n",
    "# Save to Desktop\n",
    "real_subset2.to_csv(real_path, index=False)\n",
    "synth_subset2.to_csv(synth_path, index=False)\n",
    "\n",
    "print(f\"Saved to:\\n{real_path}\\n{synth_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bdd6f0bd-22a9-4d96-8267-91ca5bb90052",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_columns3 = ['age', 'sex', 'marstat', 'minority', 'empstat', 'birthplace', 'tenure']\n",
    "\n",
    "real_subset3 = real_clean[subset_columns3].copy()\n",
    "synth_subset3 = synth_clean[subset_columns3].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "df61ba35-e0f2-4f02-968b-d20292610401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved datasets with 6 keys + target (tenure)!\n"
     ]
    }
   ],
   "source": [
    "real_subset3.to_csv(\"canada2011_tcap_real_tenure.csv\", index=False)\n",
    "synth_subset3.to_csv(\"canada2011_tcap_synth_tenure.csv\", index=False)\n",
    "\n",
    "print(\" Saved datasets with 6 keys + target (tenure)!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6e847d-d823-4832-921d-e3cbef625a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_subset3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c15f11-3aa9-4480-beeb-b60312af1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Build Desktop paths\n",
    "desktop = os.path.expanduser(\"~/Desktop\")\n",
    "real_path = os.path.join(desktop, \"canada2011_tcap_real_tenure.csv\")\n",
    "synth_path = os.path.join(desktop, \"canada2011_tcap_synth_tenure.csv\")\n",
    "\n",
    "# Save to Desktop\n",
    "real_subset3.to_csv(real_path, index=False)\n",
    "synth_subset3.to_csv(synth_path, index=False)\n",
    "\n",
    "print(f\"Saved to:\\n{real_path}\\n{synth_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63e8c68-6602-4fd2-8610-be3133d1387b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Pairwise Cramér's V among keys ===\n",
      "          Var1        Var2  CramersV\n",
      "0     minority  birthplace  0.614588\n",
      "1   age_binned     marstat  0.441917\n",
      "2   age_binned     empstat  0.384893\n",
      "3      marstat     empstat  0.229333\n",
      "4   age_binned  birthplace  0.143254\n",
      "5          sex     marstat  0.141738\n",
      "6      marstat  birthplace  0.109234\n",
      "7      empstat  birthplace  0.091506\n",
      "8          sex     empstat  0.090670\n",
      "9   age_binned    minority  0.059951\n",
      "10     marstat    minority  0.047601\n",
      "11  age_binned         sex  0.044468\n",
      "12    minority     empstat  0.041500\n",
      "13         sex  birthplace  0.027517\n",
      "14         sex    minority  0.017714\n",
      "\n",
      "=== Cramér's V between each key and target ===\n",
      "          Var Target  CramersV\n",
      "0    minority  relig  0.341353\n",
      "1  birthplace  relig  0.304106\n",
      "2  age_binned  relig  0.120526\n",
      "3     empstat  relig  0.100821\n",
      "4     marstat  relig  0.098789\n",
      "5         sex  relig  0.059406\n"
     ]
    }
   ],
   "source": [
    "# Weight calculation based on the statistical power using Cramer's V for each target vraiable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Loading the dataset\n",
    "# ---------------------------------------------------------\n",
    "source_file = \"/Users/idilalp/Desktop/canada2011_tcap_real_relig.csv\"\n",
    "df = pd.read_csv(source_file, encoding='latin1')\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Identifying keys and target\n",
    "# ---------------------------------------------------------\n",
    "target = 'relig'\n",
    "keys = [col for col in df.columns if col != target]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Handling continuous variable 'age' by binning\n",
    "# ---------------------------------------------------------\n",
    "if 'age' in keys:\n",
    "    # bin into 5 equal-width bins\n",
    "    est = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n",
    "    df['age_binned'] = est.fit_transform(df[['age']])\n",
    "    # replace 'age' with binned version for analysis\n",
    "    keys = [k if k != 'age' else 'age_binned' for k in keys]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Ensuring categorical type\n",
    "# ---------------------------------------------------------\n",
    "for col in keys + [target]:\n",
    "    df[col] = df[col].astype(str)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Function to compute Cramér’s V\n",
    "# ---------------------------------------------------------\n",
    "def cramers_v(x, y):\n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Compute Cramér’s V for all pairs of keys\n",
    "# ---------------------------------------------------------\n",
    "rows = []\n",
    "for i in range(len(keys)):\n",
    "    for j in range(i+1, len(keys)):\n",
    "        v = cramers_v(df[keys[i]], df[keys[j]])\n",
    "        rows.append((keys[i], keys[j], v))\n",
    "\n",
    "cramers_df = pd.DataFrame(rows, columns=['Var1', 'Var2', 'CramersV'])\n",
    "cramers_df = cramers_df.sort_values(by='CramersV', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n=== Pairwise Cramér's V among keys ===\")\n",
    "print(cramers_df.head(20))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Compute Cramér’s V between each key and target\n",
    "# ---------------------------------------------------------\n",
    "target_rows = []\n",
    "for k in keys:\n",
    "    v = cramers_v(df[k], df[target])\n",
    "    target_rows.append((k, target, v))\n",
    "\n",
    "target_cramers = pd.DataFrame(target_rows, columns=['Var', 'Target', 'CramersV'])\n",
    "target_cramers = target_cramers.sort_values(by='CramersV', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n=== Cramér's V between each key and target ===\")\n",
    "print(target_cramers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "61b606fc-8333-4bd7-9761-f7fe037d6e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Var  CramersV  Weight\n",
      "0    minority  0.341353   0.333\n",
      "1  birthplace  0.304106   0.297\n",
      "2  age_binned  0.120526   0.118\n",
      "3     empstat  0.100821   0.098\n",
      "4     marstat  0.098789   0.096\n",
      "5         sex  0.059406   0.058\n",
      "\n",
      "key_weights = {'minority': 0.333, 'birthplace': 0.297, 'age_binned': 0.118, 'empstat': 0.098, 'marstat': 0.096, 'sex': 0.058}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cramér's V results\n",
    "cramers_df = pd.DataFrame({\n",
    "    'Var': ['minority', 'birthplace', 'age_binned', 'empstat', 'marstat', 'sex'],\n",
    "    'CramersV': [0.341353, 0.304106, 0.120526, 0.100821, 0.098789, 0.059406]\n",
    "})\n",
    "\n",
    "# Normalising to sum to 1, rounded to 3 decimals\n",
    "cramers_df['Weight'] = cramers_df['CramersV'] / cramers_df['CramersV'].sum()\n",
    "cramers_df['Weight'] = cramers_df['Weight'].round(3)\n",
    "\n",
    "# Printing\n",
    "print(cramers_df)\n",
    "\n",
    "# Creating dictionary for TCAP\n",
    "key_weights = dict(zip(cramers_df['Var'], cramers_df['Weight']))\n",
    "print(\"\\nkey_weights =\", key_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "2b525b69-9f5a-4e12-ac53-864377c64d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Pairwise Cramér's V among keys ===\n",
      "          Var1        Var2  CramersV\n",
      "0     minority  birthplace  0.614588\n",
      "1   age_binned     marstat  0.441917\n",
      "2   age_binned     empstat  0.384893\n",
      "3      marstat     empstat  0.229333\n",
      "4   age_binned  birthplace  0.143254\n",
      "5          sex     marstat  0.141738\n",
      "6      marstat  birthplace  0.109234\n",
      "7      empstat  birthplace  0.091506\n",
      "8          sex     empstat  0.090670\n",
      "9   age_binned    minority  0.059951\n",
      "10     marstat    minority  0.047601\n",
      "11  age_binned         sex  0.044468\n",
      "12    minority     empstat  0.041500\n",
      "13         sex  birthplace  0.027517\n",
      "14         sex    minority  0.017714\n",
      "\n",
      "=== Cramér's V between each key and target ===\n",
      "          Var   Target  CramersV\n",
      "0  birthplace  citizen  0.734582\n",
      "1    minority  citizen  0.448024\n",
      "2  age_binned  citizen  0.146277\n",
      "3     marstat  citizen  0.132051\n",
      "4     empstat  citizen  0.049825\n",
      "5         sex  citizen  0.011891\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Loading the dataset\n",
    "# ---------------------------------------------------------\n",
    "source_file = \"/Users/idilalp/Desktop/canada2011_tcap_real_citizen.csv\"\n",
    "df = pd.read_csv(source_file, encoding='latin1')\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Identifying keys and target\n",
    "# ---------------------------------------------------------\n",
    "target = 'citizen'\n",
    "keys = [col for col in df.columns if col != target]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Handling continuous variable 'age' by binning\n",
    "# ---------------------------------------------------------\n",
    "if 'age' in keys:\n",
    "    # bin into 5 equal-width bins\n",
    "    est = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n",
    "    df['age_binned'] = est.fit_transform(df[['age']])\n",
    "    # replace 'age' with binned version for analysis\n",
    "    keys = [k if k != 'age' else 'age_binned' for k in keys]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Ensuring categorical type\n",
    "# ---------------------------------------------------------\n",
    "for col in keys + [target]:\n",
    "    df[col] = df[col].astype(str)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Function to compute Cramér’s V\n",
    "# ---------------------------------------------------------\n",
    "def cramers_v(x, y):\n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Compute Cramér’s V for all pairs of keys\n",
    "# ---------------------------------------------------------\n",
    "rows = []\n",
    "for i in range(len(keys)):\n",
    "    for j in range(i+1, len(keys)):\n",
    "        v = cramers_v(df[keys[i]], df[keys[j]])\n",
    "        rows.append((keys[i], keys[j], v))\n",
    "\n",
    "cramers_df = pd.DataFrame(rows, columns=['Var1', 'Var2', 'CramersV'])\n",
    "cramers_df = cramers_df.sort_values(by='CramersV', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n=== Pairwise Cramér's V among keys ===\")\n",
    "print(cramers_df.head(20))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Compute Cramér’s V between each key and target\n",
    "# ---------------------------------------------------------\n",
    "target_rows = []\n",
    "for k in keys:\n",
    "    v = cramers_v(df[k], df[target])\n",
    "    target_rows.append((k, target, v))\n",
    "\n",
    "target_cramers = pd.DataFrame(target_rows, columns=['Var', 'Target', 'CramersV'])\n",
    "target_cramers = target_cramers.sort_values(by='CramersV', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n=== Cramér's V between each key and target ===\")\n",
    "print(target_cramers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "c1d7d474-ec10-42cb-abe5-e30617a6dc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Var  CramersV  Weight\n",
      "0    minority  0.448024   0.294\n",
      "1  birthplace  0.734582   0.482\n",
      "2  age_binned  0.146277   0.096\n",
      "3     empstat  0.049825   0.033\n",
      "4     marstat  0.132051   0.087\n",
      "5         sex  0.011891   0.008\n",
      "\n",
      "key_weights = {'minority': 0.294, 'birthplace': 0.482, 'age_binned': 0.096, 'empstat': 0.033, 'marstat': 0.087, 'sex': 0.008}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cramér's V results\n",
    "cramers_df = pd.DataFrame({\n",
    "    'Var': ['minority', 'birthplace', 'age_binned', 'empstat', 'marstat', 'sex'],\n",
    "    'CramersV': [0.448024, 0.734582, 0.146277, 0.049825, 0.132051, 0.011891]\n",
    "})\n",
    "\n",
    "# Normalising to sum to 1, rounded to 3 decimals\n",
    "cramers_df['Weight'] = cramers_df['CramersV'] / cramers_df['CramersV'].sum()\n",
    "cramers_df['Weight'] = cramers_df['Weight'].round(3)\n",
    "\n",
    "# Printing\n",
    "print(cramers_df)\n",
    "\n",
    "# Creating dictionary for TCAP\n",
    "key_weights = dict(zip(cramers_df['Var'], cramers_df['Weight']))\n",
    "print(\"\\nkey_weights =\", key_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "4e05cc18-7283-4437-b649-447765e1ee8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Pairwise Cramér's V among keys ===\n",
      "          Var1        Var2  CramersV\n",
      "0     minority  birthplace  0.614588\n",
      "1   age_binned     marstat  0.441917\n",
      "2   age_binned     empstat  0.384893\n",
      "3      marstat     empstat  0.229333\n",
      "4   age_binned  birthplace  0.143254\n",
      "5          sex     marstat  0.141738\n",
      "6      marstat  birthplace  0.109234\n",
      "7      empstat  birthplace  0.091506\n",
      "8          sex     empstat  0.090670\n",
      "9   age_binned    minority  0.059951\n",
      "10     marstat    minority  0.047601\n",
      "11  age_binned         sex  0.044468\n",
      "12    minority     empstat  0.041500\n",
      "13         sex  birthplace  0.027517\n",
      "14         sex    minority  0.017714\n",
      "\n",
      "=== Cramér's V between each key and target ===\n",
      "          Var  Target  CramersV\n",
      "0     marstat  tenure  0.222305\n",
      "1     empstat  tenure  0.214812\n",
      "2  age_binned  tenure  0.126213\n",
      "3  birthplace  tenure  0.123499\n",
      "4    minority  tenure  0.102607\n",
      "5         sex  tenure  0.009996\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Load the dataset\n",
    "# ---------------------------------------------------------\n",
    "source_file = \"/Users/idilalp/Desktop/canada2011_tcap_real_tenure.csv\"\n",
    "df = pd.read_csv(source_file, encoding='latin1')\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Define keys and target\n",
    "# ---------------------------------------------------------\n",
    "target = 'tenure'\n",
    "keys = [col for col in df.columns if col != target]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Bin 'age' into 5 equal-width bins if present\n",
    "# ---------------------------------------------------------\n",
    "if 'age' in keys:\n",
    "    est = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n",
    "    df['age_binned'] = est.fit_transform(df[['age']])\n",
    "    keys = [k if k != 'age' else 'age_binned' for k in keys]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Convert all key and target columns to string\n",
    "# ---------------------------------------------------------\n",
    "for col in keys + [target]:\n",
    "    df[col] = df[col].astype(str)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Function to compute Cramér’s V\n",
    "# ---------------------------------------------------------\n",
    "def cramers_v(x, y):\n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Compute Cramér’s V between each pair of keys\n",
    "# ---------------------------------------------------------\n",
    "pairwise_rows = []\n",
    "for i in range(len(keys)):\n",
    "    for j in range(i+1, len(keys)):\n",
    "        v = cramers_v(df[keys[i]], df[keys[j]])\n",
    "        pairwise_rows.append((keys[i], keys[j], v))\n",
    "\n",
    "cramers_df = pd.DataFrame(pairwise_rows, columns=['Var1', 'Var2', 'CramersV'])\n",
    "cramers_df = cramers_df.sort_values(by='CramersV', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n=== Pairwise Cramér's V among keys ===\")\n",
    "print(cramers_df.head(20))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Compute Cramér’s V between each key and the target\n",
    "# ---------------------------------------------------------\n",
    "target_rows = []\n",
    "for k in keys:\n",
    "    v = cramers_v(df[k], df[target])\n",
    "    target_rows.append((k, target, v))\n",
    "\n",
    "target_cramers = pd.DataFrame(target_rows, columns=['Var', 'Target', 'CramersV'])\n",
    "target_cramers = target_cramers.sort_values(by='CramersV', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n=== Cramér's V between each key and target ===\")\n",
    "print(target_cramers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "deb93ecb-f485-47dd-9fd6-f420513f68c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Var  CramersV  Weight\n",
      "0    minority  0.102607   0.128\n",
      "1  birthplace  0.123499   0.154\n",
      "2  age_binned  0.126213   0.158\n",
      "3     empstat  0.214812   0.269\n",
      "4     marstat  0.222305   0.278\n",
      "5         sex  0.009996   0.013\n",
      "\n",
      "key_weights = {'minority': 0.128, 'birthplace': 0.154, 'age_binned': 0.158, 'empstat': 0.269, 'marstat': 0.278, 'sex': 0.013}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cramér's V results\n",
    "cramers_df = pd.DataFrame({\n",
    "    'Var': ['minority', 'birthplace', 'age_binned', 'empstat', 'marstat', 'sex'],\n",
    "    'CramersV': [0.102607, 0.123499, 0.126213, 0.214812, 0.222305, 0.009996]\n",
    "})\n",
    "\n",
    "# Normalize to sum to 1 and round to 3 decimals\n",
    "cramers_df['Weight'] = cramers_df['CramersV'] / cramers_df['CramersV'].sum()\n",
    "cramers_df['Weight'] = cramers_df['Weight'].round(3)\n",
    "\n",
    "# Print DataFrame\n",
    "print(cramers_df)\n",
    "\n",
    "# Create dictionary for TCAP input\n",
    "key_weights = dict(zip(cramers_df['Var'], cramers_df['Weight']))\n",
    "print(\"\\nkey_weights =\", key_weights)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
